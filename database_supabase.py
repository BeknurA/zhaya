import os
import streamlit as st
from supabase import create_client, Client
import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any
import hashlib
import json


# =================================================================
# === –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø SUPABASE ===
# =================================================================

def get_supabase_config():
    """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é Supabase"""
    try:
        if hasattr(st, 'secrets') and 'supabase' in st.secrets:
            return {
                'url': st.secrets['supabase']['url'],
                'key': st.secrets['supabase']['key'],
                'db_url': st.secrets['supabase']['db_url']
            }
        else:
            return {
                'url': os.getenv('SUPABASE_URL'),
                'key': os.getenv('SUPABASE_KEY'),
                'db_url': os.getenv('SUPABASE_DB_URL')
            }
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Supabase: {e}")
        return None


@st.cache_resource
def init_supabase():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç Supabase —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π"""
    config = get_supabase_config()
    if not config or not all(config.values()):
        st.error("‚ö†Ô∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Supabase –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return None

    try:
        supabase: Client = create_client(config['url'], config['key'])
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        response = supabase.table('production_batches').select('count', count='exact').limit(1).execute()
        return supabase
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {e}")
        return None


# =================================================================
# === –ö–≠–®–ò–†–û–í–ê–ù–ò–ï –° –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ú –£–î–ê–õ–ï–ù–ò–ï–ú ===
# =================================================================

def get_cache_key(*args) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤"""
    key_str = "_".join(str(arg) for arg in args)
    return hashlib.md5(key_str.encode()).hexdigest()


@st.cache_data(ttl=300)  # 5 –º–∏–Ω—É—Ç
def fetch_production_batches_cached(limit: int = 100):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä—Ç–∏–π"""
    return fetch_production_batches(limit)


@st.cache_data(ttl=180)  # 3 –º–∏–Ω—É—Ç—ã
def fetch_lab_measurements_cached(batch_id: int = None):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–º–µ—Ä–µ–Ω–∏–π"""
    return fetch_lab_measurements(batch_id)


@st.cache_data(ttl=600)  # 10 –º–∏–Ω—É—Ç –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤
def fetch_dashboard_config_cached():
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–∞—à–±–æ—Ä–¥–∞"""
    return fetch_dashboard_config()


@st.cache_data(ttl=600)
def fetch_reports_config_cached():
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤"""
    return fetch_reports_config()


def clear_all_caches():
    """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –∫—ç—à–µ–π"""
    st.cache_data.clear()
    st.cache_resource.clear()


# =================================================================
# === –ü–†–û–ò–ó–í–û–î–°–¢–í–ï–ù–ù–´–ï –ü–ê–†–¢–ò–ò ===
# =================================================================
def fetch_activity_logs(limit: int = 100):
    """–ü–æ–ª—É—á–∞–µ—Ç –ª–æ–≥–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    supabase = init_supabase()
    if not supabase:
        return pd.DataFrame()

    try:
        response = supabase.table('activity_logs') \
            .select('*, users(full_name, username)') \
            .order('timestamp', desc=True) \
            .limit(limit) \
            .execute()

        if response.data:
            df = pd.DataFrame(response.data)
            # –†–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ —Å–ª–æ–≤–∞—Ä—è –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            if 'users' in df.columns:
                user_df = pd.json_normalize(df['users'])
                user_df.rename(columns={'full_name': 'full_name', 'username': 'username'}, inplace=True)
                df = df.drop(columns=['users']).join(user_df)
            return df
        return pd.DataFrame()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ª–æ–≥–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏: {e}")
        return pd.DataFrame()


def create_production_batch(product_type: str, target_concentration: float,
                            initial_weight: float, user_id: str = None) -> Optional[Dict]:
    """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—É—é –ø–∞—Ä—Ç–∏—é —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    supabase = init_supabase()
    if not supabase:
        return None

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    if target_concentration < 0 or target_concentration > 15:
        st.error("–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ç 0 –¥–æ 15%")
        return None

    if initial_weight <= 0:
        st.error("–í–µ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º —á–∏—Å–ª–æ–º")
        return None

    try:
        data = {
            'product_type': product_type,
            'target_sea_buckthorn_concentration': target_concentration,
            'initial_weight': initial_weight
        }
        response = supabase.table('production_batches').insert(data).execute()

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        if response.data and user_id:
            log_user_action(user_id, "create_batch", f"–°–æ–∑–¥–∞–Ω–∞ –ø–∞—Ä—Ç–∏—è ID: {response.data[0]['batch_id']}")

        # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞
        clear_all_caches()

        return response.data[0] if response.data else None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞—Ä—Ç–∏–∏: {e}")
        return None


def fetch_production_batches(limit: int = 100) -> pd.DataFrame:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–∞—Ä—Ç–∏–π"""
    supabase = init_supabase()
    if not supabase:
        return pd.DataFrame()

    try:
        response = supabase.table('production_batches') \
            .select('*') \
            .order('created_at', desc=True) \
            .limit(limit) \
            .execute()
        return pd.DataFrame(response.data) if response.data else pd.DataFrame()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞—Ä—Ç–∏–π: {e}")
        return pd.DataFrame()


def fetch_iot_sensor_data(batch_id: int = None, limit: int = 1000):
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ IoT —Å–µ–Ω—Å–æ—Ä–æ–≤"""
    supabase = init_supabase()
    if not supabase:
        return pd.DataFrame()

    try:
        query = supabase.table('iot_sensor_data') \
            .select('*') \
            .order('time', desc=True) \
            .limit(limit)

        if batch_id:
            query = query.eq('batch_id', batch_id)

        response = query.execute()
        return pd.DataFrame(response.data) if response.data else pd.DataFrame()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å–µ–Ω—Å–æ—Ä–æ–≤: {e}")
        return pd.DataFrame()
def update_batch_weight(batch_id: int, final_weight: float, user_id: str = None) -> bool:
    """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –≤–µ—Å –ø–∞—Ä—Ç–∏–∏"""
    supabase = init_supabase()
    if not supabase:
        return False

    if final_weight <= 0:
        st.error("–í–µ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º")
        return False

    try:
        response = supabase.table('production_batches') \
            .update({'final_weight': final_weight, 'end_time': datetime.utcnow().isoformat()}) \
            .eq('batch_id', batch_id) \
            .execute()

        if user_id:
            log_user_action(user_id, "update_batch", f"–û–±–Ω–æ–≤–ª–µ–Ω –≤–µ—Å –ø–∞—Ä—Ç–∏–∏ {batch_id}: {final_weight} –∫–≥")

        clear_all_caches()
        return bool(response.data)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
        return False


# =================================================================
# === –õ–ê–ë–û–†–ê–¢–û–†–ù–´–ï –ò–ó–ú–ï–†–ï–ù–ò–Ø ===
# =================================================================

def add_lab_measurement(batch_id: int, parameter_name: str, parameter_value: float,
                        parameter_unit: str, lab_technician: str = None,
                        notes: str = None, user_id: str = None) -> bool:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    supabase = init_supabase()
    if not supabase:
        return False

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
    valid_params = get_parameter_options()
    if parameter_name not in valid_params:
        st.error(f"–ù–µ–≤–µ—Ä–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä. –î–æ–ø—É—Å—Ç–∏–º—ã–µ: {', '.join(valid_params)}")
        return False

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–Ω–∞—á–µ–Ω–∏—è
    if parameter_value < 0:
        st.warning("–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞")

    try:
        data = {
            'batch_id': batch_id,
            'parameter_name': parameter_name,
            'parameter_value': parameter_value,
            'parameter_unit': parameter_unit,
            'lab_technician': lab_technician,
            'notes': notes
        }
        response = supabase.table('lab_measurements').insert(data).execute()

        if user_id:
            log_user_action(user_id, "add_measurement",
                            f"–î–æ–±–∞–≤–ª–µ–Ω–æ –∏–∑–º–µ—Ä–µ–Ω–∏–µ {parameter_name} –¥–ª—è –ø–∞—Ä—Ç–∏–∏ {batch_id}")

        clear_all_caches()
        return bool(response.data)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–∑–º–µ—Ä–µ–Ω–∏—è: {e}")
        return False


def fetch_lab_measurements(batch_id: int = None) -> pd.DataFrame:
    """–ü–æ–ª—É—á–∞–µ—Ç –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è"""
    supabase = init_supabase()
    if not supabase:
        return pd.DataFrame()

    try:
        query = supabase.table('lab_measurements') \
            .select('*, production_batches(product_type, batch_id)') \
            .order('measurement_time', desc=True)

        if batch_id:
            query = query.eq('batch_id', batch_id)

        response = query.execute()
        return pd.DataFrame(response.data) if response.data else pd.DataFrame()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑–º–µ—Ä–µ–Ω–∏–π: {e}")
        return pd.DataFrame()


# =================================================================
# === –î–ê–®–ë–û–†–î–´ –ò –û–¢–ß–ï–¢–´ –ò–ó –ë–î ===
# =================================================================

def fetch_dashboard_config() -> Optional[Dict]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–∞—à–±–æ—Ä–¥–∞ –∏–∑ –ë–î"""
    supabase = init_supabase()
    if not supabase:
        return None

    try:
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–∞–±–ª–∏—Ü—ã dashboard_config
        response = supabase.table('dashboard_config') \
            .select('*') \
            .eq('is_active', True) \
            .execute()

        if response.data:
            return response.data[0]

        # –ï—Å–ª–∏ –Ω–µ—Ç –≤ –ë–î, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        return get_default_dashboard_config()
    except:
        return get_default_dashboard_config()


def get_default_dashboard_config() -> Dict:
    """–î–µ—Ñ–æ–ª—Ç–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–∞—à–±–æ—Ä–¥–∞"""
    return {
        "title": "–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π Dashboard",
        "kpis": [
            {"name": "production_today", "label": "–ü—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–æ —Å–µ–≥–æ–¥–Ω—è", "unit": "–∫–≥"},
            {"name": "yield_pct", "label": "–í—ã—Ö–æ–¥ –ø—Ä–æ–¥—É–∫—Ü–∏–∏", "unit": "%"},
            {"name": "avg_ph", "label": "–°—Ä–µ–¥–Ω–∏–π pH", "unit": ""},
            {"name": "active_batches", "label": "–ê–∫—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä—Ç–∏–π", "unit": ""},
            {"name": "efficiency", "label": "OEE —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å", "unit": "%"}
        ],
        "charts": [
            {"type": "production_week", "title": "–î–∏–Ω–∞–º–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞"},
            {"type": "ph_stages", "title": "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ pH"},
            {"type": "quality_pie", "title": "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É"}
        ]
    }


def fetch_reports_config() -> List[Dict]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –æ—Ç—á–µ—Ç–æ–≤ –∏–∑ –ë–î"""
    supabase = init_supabase()
    if not supabase:
        return get_default_reports_config()

    try:
        response = supabase.table('reports_config') \
            .select('*') \
            .eq('is_active', True) \
            .order('display_order') \
            .execute()

        if response.data:
            return response.data

        return get_default_reports_config()
    except:
        return get_default_reports_config()


def get_default_reports_config() -> List[Dict]:
    """–î–µ—Ñ–æ–ª—Ç–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤"""
    return [
        {
            "report_id": "production",
            "name": "–ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ç—á–µ—Ç",
            "description": "–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥",
            "icon": "üìÖ",
            "sections": ["kpi", "production_table", "charts"]
        },
        {
            "report_id": "quality",
            "name": "–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞",
            "description": "–ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π",
            "icon": "üìà",
            "sections": ["quality_metrics", "ph_analysis", "oxidation"]
        },
        {
            "report_id": "economic",
            "name": "–≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏",
            "description": "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞",
            "icon": "üí∞",
            "sections": ["revenue", "costs", "profitability"]
        }
    ]


def save_dashboard_config(config: Dict, user_id: str) -> bool:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–∞—à–±–æ—Ä–¥–∞"""
    supabase = init_supabase()
    if not supabase:
        return False

    try:
        # –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        supabase.table('dashboard_config').update({'is_active': False}).execute()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–æ–≤—É—é
        config['is_active'] = True
        config['updated_by'] = user_id
        config['updated_at'] = datetime.utcnow().isoformat()

        response = supabase.table('dashboard_config').insert(config).execute()

        log_user_action(user_id, "update_dashboard_config", "–û–±–Ω–æ–≤–ª–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–∞—à–±–æ—Ä–¥–∞")
        clear_all_caches()

        return bool(response.data)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return False


# =================================================================
# === –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –î–ï–ô–°–¢–í–ò–ô ===
# =================================================================

def log_user_action(user_id: str, action: str, details: str = "", metadata: Dict = None):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    supabase = init_supabase()
    if not supabase:
        return

    try:
        log_data = {
            'user_id': user_id,
            'action': action,
            'details': details,
            'timestamp': datetime.utcnow().isoformat()
        }

        if metadata:
            log_data['metadata'] = json.dumps(metadata)

        supabase.table('activity_logs').insert(log_data).execute()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")


def fetch_activity_logs(user_id: str = None, limit: int = 100) -> pd.DataFrame:
    """–ü–æ–ª—É—á–∞–µ—Ç –ª–æ–≥–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
    supabase = init_supabase()
    if not supabase:
        return pd.DataFrame()

    try:
        query = supabase.table('activity_logs') \
            .select('*') \
            .order('timestamp', desc=True) \
            .limit(limit)

        if user_id:
            query = query.eq('user_id', user_id)

        response = query.execute()
        return pd.DataFrame(response.data) if response.data else pd.DataFrame()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ª–æ–≥–æ–≤: {e}")
        return pd.DataFrame()


# =================================================================
# === –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò –ê–ù–ê–õ–ò–¢–ò–ö–ê ===
# =================================================================

@st.cache_data(ttl=300)
def get_production_statistics(date_from: datetime, date_to: datetime) -> Dict:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥"""
    supabase = init_supabase()
    if not supabase:
        return {}

    try:
        # –ü–∞—Ä—Ç–∏–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥
        batches = supabase.table('production_batches') \
            .select('*') \
            .gte('start_time', date_from.isoformat()) \
            .lte('start_time', date_to.isoformat()) \
            .execute()

        df = pd.DataFrame(batches.data) if batches.data else pd.DataFrame()

        if df.empty:
            return {}

        stats = {
            'total_batches': len(df),
            'total_weight': df['initial_weight'].sum(),
            'avg_concentration': df['target_sea_buckthorn_concentration'].mean(),
            'product_types': df['product_type'].value_counts().to_dict()
        }

        return stats
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        return {}


def get_batch_details(batch_id: int):
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä—Ç–∏–∏"""
    supabase = init_supabase()
    if not supabase:
        return None

    try:
        # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞—Ä—Ç–∏–∏
        batch_response = supabase.table('production_batches') \
            .select('*') \
            .eq('batch_id', batch_id) \
            .execute()

        if not batch_response.data:
            return None

        batch_data = batch_response.data[0]

        # –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è
        lab_data = fetch_lab_measurements(batch_id)

        # –î–∞–Ω–Ω—ã–µ —Å–µ–Ω—Å–æ—Ä–æ–≤
        sensor_data = fetch_iot_sensor_data(batch_id, limit=100)

        # –≠—Ç–∞–ø—ã –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞
        stages_response = supabase.table('production_stages') \
            .select('*') \
            .eq('batch_id', batch_id) \
            .order('stage_order') \
            .execute()

        stages_data = pd.DataFrame(stages_response.data) if stages_response.data else pd.DataFrame()

        return {
            'batch_info': batch_data,
            'lab_measurements': lab_data,
            'sensor_data': sensor_data,
            'production_stages': stages_data
        }
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π –ø–∞—Ä—Ç–∏–∏: {e}")
        return None
# =================================================================
# === –£–¢–ò–õ–ò–¢–´ ===
# =================================================================

def get_parameter_options() -> List[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    return [
        'W', 'S', 'pH', 'ORP', 'protein', 'fat', 'ash', 'C_L', 'C_a', 'C_b',
        'WBC', 'WRC', 'FBC', 'TBARS', 'peroxide_value', 'antioxidants',
        'beta_carotene', 'flavonoids', 'vitamin_c', 'vitamin_e', 'TAMC'
    ]


def get_product_types() -> List[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∏–ø—ã –ø—Ä–æ–¥—É–∫—Ç–æ–≤"""
    return ['–ñ–∞—è', '–§–æ—Ä–º–æ–≤–∞–Ω–Ω–æ–µ –º—è—Å–æ']


def validate_batch_data(data: Dict) -> tuple[bool, str]:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä—Ç–∏–∏"""
    if 'product_type' not in data or data['product_type'] not in get_product_types():
        return False, "–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –ø—Ä–æ–¥—É–∫—Ç–∞"

    if data.get('target_sea_buckthorn_concentration', 0) > 15:
        return False, "–ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–µ–≤—ã—à–∞—Ç—å 15%"

    if data.get('initial_weight', 0) <= 0:
        return False, "–í–µ—Å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º"

    return True, "OK"